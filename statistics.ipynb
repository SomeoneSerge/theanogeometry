{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # This file is part of Theano Geometry\n",
    "#\n",
    "# Copyright (C) 2017, Stefan Sommer (sommer@di.ku.dk)\n",
    "# https://bitbucket.org/stefansommer/theanogemetry\n",
    "#\n",
    "# Theano Geometry is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# Theano Geometry is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with Theano Geometry. If not, see <http://www.gnu.org/licenses/>.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manifold Statistics - Examples on $\\mathbb{S}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manifolds.S2 import *\n",
    "M = S2()\n",
    "print(M)\n",
    "\n",
    "from src.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Riemannian structure\n",
    "from src.Riemannian import metric\n",
    "metric.initialize(M)\n",
    "\n",
    "# geodesics\n",
    "from src.Riemannian import geodesic\n",
    "geodesic.initialize(M)\n",
    "\n",
    "# Logarithm map\n",
    "from src.Riemannian import Log\n",
    "Log.initialize(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate form\n",
    "from src.stochastics import Brownian_coords\n",
    "Brownian_coords.initialize(M)\n",
    "\n",
    "N_samples = 20\n",
    "x = np.zeros((M.dim.eval()))\n",
    "\n",
    "samples = np.zeros((N_samples,M.dim.eval()))\n",
    "for i in range(N_samples):\n",
    "    (ts,xs) = M.Brownian_coordsf(x,dWsf(M.dim.eval()))\n",
    "    samples[i] = xs[-1]\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "for i in range(N_samples):\n",
    "    M.plotx(samples[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.statistics.Frechet_mean import *\n",
    "\n",
    "res = Frechet_mean(M,lambda *args: M.Logf(*args), samples)\n",
    "Fm = res[0]\n",
    "print(\"loss = \", res[1])\n",
    "print(\"mean = \", Fm)\n",
    "iterations = res[2]\n",
    "\n",
    "newfig()\n",
    "M.plot(rotate = np.array([50,-45]))\n",
    "M.plotx(Fm)\n",
    "M.plotx(iterations)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet mean on FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samp = 5\n",
    "y0 = np.random.normal(0., 0.2, (n_samp,2))\n",
    "\n",
    "x0 = np.array([0.4,0.]).astype(theano.config.floatX)\n",
    "ui0 = np.array([1,0,0,1])\n",
    "q0 = np.hstack([x0,ui0.flatten()]).astype(theano.config.floatX)\n",
    "print(q0)\n",
    "\n",
    "v0 = np.array([-1.,0.]).astype(theano.config.floatX)\n",
    "v0 = GramSchmidt(v0,x0)\n",
    "p0 = gMflatf(x0,v0)\n",
    "#xia0 = np.zeros(4)\n",
    "#p0 = np.hstack([xi0,xia0])\n",
    "print(p0)\n",
    "\n",
    "from src.FM import *\n",
    "\n",
    "qsv = Expfm(q0,p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.FM import *\n",
    "\n",
    "detg = lambda x,u: T.nlinalg.Det()(T.tensordot(u.T,T.tensordot(g(x),u,axes=(1,0)),axes=(1,0)))\n",
    "\n",
    "def loss(m,dat): \n",
    "    \n",
    "    u = m[0:(d+rank*d)]\n",
    "    v = m[(d+rank*d):].reshape((n_samp,d))\n",
    "    \n",
    "    (cout, updates) = theano.scan(fn = lambda v,q: Expfm(q,gMflat(q,v))[0:d],\n",
    "                                  sequences = [v],\n",
    "                                  non_sequences = [u],\n",
    "                                  n_steps=n_samp)\n",
    "    \n",
    "    #T.sum(h_v**2)\n",
    "    return cout #1./n_samp*(T.sum(v**2) + lambda0*T.sum((cout - dat)**2)) - 1./2*T.log()\n",
    "\n",
    "m = T.vector() # frame and horizontal vectors\n",
    "dat = T.matrix()\n",
    "lossf = theano.function([m,dat], loss(m,dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y0 = np.random.normal(0., 0.2, (n_samp,2))\n",
    "\n",
    "q0 = np.array([0.,0.]).astype(theano.config.floatX)\n",
    "v0 = y0 - q0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(q0.shape)\n",
    "print(p0.shape)\n",
    "def Log(x0, y, Fr):\n",
    "    def fopts(x):\n",
    "#         print(Ttype(np.vstack([concatx(x0,Fr.flatten()),x])),)\n",
    "        y = lossf(np.vstack([concatx(x0,Fr.flatten()),x]),1./n_steps.eval(),n_steps.eval())\n",
    "        return y\n",
    "\n",
    "    res = minimize(fopts, np.zeros([d.eval()+rank.eval()*d.eval()]), method='CG', jac=False, options={'disp': False, 'maxiter': 50})\n",
    "    return res.x\n",
    "Logf(q0,data[i,:],p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.Hamiltonian import *\n",
    "\n",
    "data = y0\n",
    "q0 = np.array([0.3,0.]).astype(theano.config.floatX)\n",
    "p0 = np.array([1,0,0,1])\n",
    "u0 = np.hstack((q0,p0))\n",
    "\n",
    "#Logyis = np.zeros((Nsamples,d+d*rank))\n",
    "openPool()\n",
    "\n",
    "def Log(x0, y, Fr):\n",
    "    def fopts(x):\n",
    "#         print(Ttype(np.vstack([concatx(x0,Fr.flatten()),x])),)\n",
    "        y = lossf(np.vstack([concatx(x0,Fr.flatten()),x]),1./n_steps.eval(),n_steps.eval())\n",
    "        return y\n",
    "\n",
    "    res = minimize(fopts, np.zeros([d.eval()+rank.eval()*d.eval()]), method='CG', jac=False, options={'disp': False, 'maxiter': 50})\n",
    "    return res.x\n",
    "\n",
    "print(\"shooting for initial Logs\")\n",
    "def lLog(i):\n",
    "    return Log(q0, data[i,:], p0)\n",
    "print(lLog(1))\n",
    "#sol = pool.imap(lLog, zip(*(np.arange(n_samp),)) )\n",
    "#print(sol)\n",
    "#Logyis = np.array(list(sol)) \n",
    "\n",
    "closePool()\n",
    "\n",
    "#MPPLogf(1,u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unconstrained penalized version\n",
    "from scipy.optimize import minimize,fmin_bfgs,fmin_cg,fmin_l_bfgs_b,approx_fprime, check_grad\n",
    "import\n",
    "\n",
    "def DiffSource(data, tol=1e-4, maxIter=20, x0=None, Xa0=None, Logyis=None):\n",
    "\n",
    "    def MPPLogf(idx,m):\n",
    "        Nsamples = (m.shape[0]-(d+d*rank))/(d+d*rank)\n",
    "        q0 = 1e-2*m[0:d+d*rank]\n",
    "        Logsamples = m[d+d*rank:].reshape([Nsamples,d+d*rank])\n",
    "\n",
    "        f = lambda xx: lossf(Ttype(np.vstack([concatx(x0,Xa0.flatten()),xx])),1./n_steps0,n_steps0)\n",
    "        y = f(Logsamples[idx,:])\n",
    "\n",
    "        return (y,)\n",
    "\n",
    "    def dMPPLogf(idx,m):\n",
    "        Nsamples = (m.shape[0]-(d+d*rank))/(d+d*rank)\n",
    "        x0 = 1e-2*m[0:d]\n",
    "        Xa0 = 1e-2*m[d:d+d*rank].reshape([d,rank])\n",
    "        Logsamples = m[d+d*rank:].reshape([Nsamples,d+d*rank])\n",
    "        \n",
    "        qtarget0.set_value(Ttype(data[idx,:]))\n",
    "        f = lambda xx: lossf(Ttype(xx).reshape([2,d+rank*d]),1./n_steps0,n_steps0)\n",
    "        gy = approx_fprime(np.vstack([concatx(x0,Xa0.flatten()),Logsamples[idx,:].flatten()]).flatten(),f,1e-5)\n",
    "    \n",
    "        return (gy,)\n",
    "    \n",
    "    \n",
    "    def f(m):\n",
    "        # energy\n",
    "        Nsamples = (m.shape[0]-(d+d*rank))/(d+d*rank)\n",
    "\n",
    "        EHs = np.empty(Nsamples)\n",
    "        x0 = 1e-2*m[0:d]\n",
    "        Xa0 = 1e-2*m[d:d+d*rank].reshape([d,rank])\n",
    "        Logsamples = m[d+d*rank:].reshape([Nsamples,d+d*rank])\n",
    "        \n",
    "        for idx in range(Nsamples):\n",
    "            xi = Logsamples[idx,0:d]\n",
    "            Xia = Logsamples[idx,d:d+d*rank].reshape([d,rank])            \n",
    "            EHs[i] = Hsplitf(x0,Xa0,xi,Xia)\n",
    "\n",
    "        res = (1./Nsamples)*np.sum(EHs)\n",
    "        detXa02 = detg2f(x0,Xa0)\n",
    "        Xa02inner = np.einsum('ba,bi,ij->aj',Xa0,gf(x0),Xa0)\n",
    "#         print(\"f x0: %s, Xa02 diag: %s, Xa02 off: %s, det: %g, res %g, logstuff %g\" % (x0,np.diag(Xa02inner),Xa02inner[0,1],detXa02,res,(1./2.)*np.log(detXa02)))\n",
    "#         print(\"f Xa02 diag: %s, Xa02 off: %s, det: %g, res %g, logstuff %g\" % (np.diag(Xa02inner),Xa02inner[0,1],detXa02,res,(1./2.)*np.log(detXa02)))\n",
    "        return 1e0*(res + .5*np.log(detXa02))\n",
    "    \n",
    "    def constr(m):\n",
    "        # parallel compute distances        \n",
    "        Nsamples = (m.shape[0]-(d+d*rank))/(d+d*rank)\n",
    "\n",
    "        sol = pool.imap(MPPLogf, zip(*(xrange(Nsamples), itertools.cycle((m,)))) )\n",
    "        res = list(sol)\n",
    "        Logs = getRes(res,0)\n",
    "\n",
    "#         res = 1e-3-(1./Nsamples)*np.sum(Logs)\n",
    "        res = 1e-5-Logs\n",
    "        return res\n",
    "\n",
    "    def dconstr(m):\n",
    "        # parallel compute distances        \n",
    "        Nsamples = (m.shape[0]-(d+d*rank))/(d+d*rank)\n",
    "\n",
    "        sol = pool.imap(dMPPLogf, zip(*(xrange(Nsamples), itertools.cycle((m,)))) )\n",
    "        res = list(sol)\n",
    "        dLogsres = getRes(res,0)\n",
    "        dLogs = np.zeros([Nsamples,m.shape[0]])\n",
    "        for i in range(Nsamples):\n",
    "            dLogs[i,0:d+rank*d] = 1e-2*dLogsres[i,0:d+d*rank]\n",
    "            dLogs[i,d+rank*d+i*(d+rank*d):d+rank*d+(i+1)*(d+rank*d)] = dLogsres[i,d+d*rank:2*(d+rank*d)]\n",
    "        \n",
    "\n",
    "#         res = 1e-3-(1./Nsamples)*np.sum(Logs)\n",
    "#         res = 1e-4-np.sum(Logs)\n",
    "        dres = -dLogs\n",
    "        return dres\n",
    "            \n",
    "        \n",
    "    # number of samples\n",
    "    Nsamples = data.shape[0]\n",
    "            \n",
    "    if x0 == None:\n",
    "        # initial point\n",
    "        x0 = np.mean(data,0)\n",
    "    if Xa0 == None:\n",
    "        # initial frame        \n",
    "        Gx0M = gf(x0)\n",
    "        Xa0 = np.eye(d)\n",
    "        Xa0 = np.linalg.solve(sp.linalg.sqrtm(Gx0M),Xa0) # make orthonormal\n",
    "\n",
    "    print(\"initial point/frame, x0: %s, Xa0: %s\" % (x0,Xa0))\n",
    "    \n",
    "    openPool()\n",
    "    \n",
    "    if Logyis == None:\n",
    "        #Logyis = np.zeros((Nsamples,d+d*rank))\n",
    "        print(\"shooting for initial Logs\")\n",
    "        def lLog(i):\n",
    "            return Log(x0, data[i,:], Fr)\n",
    "        sol = pool.imap(lLog, zip(*(xrange(Nsamples),)) )\n",
    "        Logyis = np.array(list(sol))    \n",
    "\n",
    "    initval = np.hstack( (1e2*x0,1e2*Xa0.flatten(),Logyis.flatten(),) )\n",
    "    \n",
    "#     print(\"checking constr gradient\")\n",
    "#     for i in range(Nsamples):\n",
    "#         err = check_grad(lambda x: constr(x)[i],lambda x: dconstr(x)[i],initval)\n",
    "#         print(\"sampe %i contr grad erro %g\" % (i,err))\n",
    "#         if err > 1:\n",
    "#             print(dconstr(initval)[i])\n",
    "#             print(approx_fprime(initval,lambda x: constr(x)[i],1e-5))\n",
    "    \n",
    "    print(\"running constrained optimization\")\n",
    "    res = minimize(f, initval, method='SLSQP',\\\n",
    "                   tol=tol,\\\n",
    "                   constraints={'type': 'ineq', 'fun': constr, 'jac': dconstr},\\\n",
    "                   options={'disp': True, 'maxiter': maxIter},\\\n",
    "                   )\n",
    "    closePool()\n",
    "    \n",
    "    if not res.success:\n",
    "        print(\"mean/covar optimization failed:\\n%s\" % res)\n",
    "    mu = 1e-2*res.x[0:d]\n",
    "    SigmaSQRT = 1e-2*res.x[d:d+d*rank]\n",
    "    Logyis = res.x[d+d*rank:].reshape([Nsamples,d+d*rank])\n",
    "\n",
    "    return (mu,SigmaSQRT,Logyis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DiffSource(y0, tol=1e-4, maxIter=20, x0=None, Xa0=None, Logyis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownian motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.Brownian_Stochastic_Development import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observation\n",
    "x0 = np.array([0.,0.]).astype(theano.config.floatX)\n",
    "\n",
    "# Frame\n",
    "v0 = np.array([[0.4,0],[0.,0.4]]).astype(theano.config.floatX)\n",
    "ui0 = v0 #GramSchmidt(v0,x0) #sp.linalg.orth(v0) # Gram-Schmidt\n",
    "\n",
    "q0 = np.hstack([x0,ui0.flatten()]).astype(theano.config.floatX)\n",
    "\n",
    "n_steps.set_value(1000)\n",
    "dWt0 = np.random.normal(0, np.sqrt(dt.eval()), (n_steps.get_value(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wt0 = np.cumsum(dWt0, axis=0)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(np.hstack((0,Wt0[:,0])),np.hstack((0,Wt0[:,1])),'b-',\n",
    "        linewidth=1)\n",
    "plt.plot(0,0,'ro',markersize=10.)\n",
    "plt.plot(Wt0[-1,0],Wt0[-1,1],'go',markersize=10.)\n",
    "#plt.savefig(\"Brown1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Brownian motion:\n",
    "Bt = SD_brownian(q0,2,dWt0)\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "newfig()\n",
    "plotM(rotate = np.array([50,-45]))\n",
    "plotFMx(Bt)\n",
    "plt.show()\n",
    "#plt.savefig(\"Brown.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observation\n",
    "x0 = np.array([0.,0.]).astype(theano.config.floatX)\n",
    "\n",
    "# Frame\n",
    "v0 = np.array([[0.1,0.2],[0.2,0.2]]).astype(theano.config.floatX)\n",
    "ui0 = v0#0.3*GramSchmidt(v0,x0) #sp.linalg.orth(v0) # Gram-Schmidt\n",
    "print(ui0)\n",
    "q0 = np.hstack([x0,ui0.flatten()]).astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.normal_dist import *\n",
    "a = normal_dist_sample(5000,q0)[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "#plt.rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "aa = np.zeros((a.shape[0],3))\n",
    "for i in range(a.shape[0]):\n",
    "    aa[i,:] = Ff(a[i,:])\n",
    "    \n",
    "newfig()\n",
    "plotM(rotate = np.array([55,0]))\n",
    "plot_density_estimate(aa, alpha = 0.9)\n",
    "#plt.show()\n",
    "#plt.savefig(\"Anisonorm.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
