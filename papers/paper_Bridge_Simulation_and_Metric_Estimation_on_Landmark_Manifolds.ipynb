{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # This file is part of Theano Geometry\n",
    "#\n",
    "# Copyright (C) 2017, Stefan Sommer (sommer@di.ku.dk)\n",
    "# https://bitbucket.org/stefansommer/theanogemetry\n",
    "#\n",
    "# Theano Geometry is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# Theano Geometry is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with Theano Geometry. If not, see <http://www.gnu.org/licenses/>.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Brownian Bridge Simulation and Metric Estimation on Landmark Manifolds\n",
    "arXiv:1705.10943 [cs.CV] https://arxiv.org/abs/1705.10943\n",
    "\n",
    "Stefan Sommer, Line Kuhnel, Alexis Arnaudon, and Sarang Joshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from src.manifolds.landmarks import *\n",
    "M = landmarks(2)\n",
    "print(M)\n",
    "\n",
    "from src.plotting import *\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 13, 10\n",
    "colormap = plt.get_cmap('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Riemannian structure\n",
    "from src.Riemannian import metric\n",
    "metric.initialize(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "M.N.set_value(8)\n",
    "M.k_alpha.set_value(.1)\n",
    "M.k_sigma.set_value(.5*np.diag((1.,1.)))\n",
    "n_steps.set_value(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup \n",
    "q = np.vstack((np.linspace(-.5,.5,M.N.eval()),np.zeros(M.N.eval()))).T.flatten()\n",
    "v = np.vstack((np.zeros(M.N.eval()),np.ones(M.N.eval()))).T.flatten()\n",
    "p = M.flatf(q,v)\n",
    "print(\"q = \", q)\n",
    "print(\"p = \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hamiltonian dynamics\n",
    "print(M.Hf(q,p))\n",
    "from src.dynamics import Hamiltonian\n",
    "Hamiltonian.initialize(M)\n",
    "\n",
    "# geodesic\n",
    "qs = M.Exp_Hamiltoniantf(q,v).T\n",
    "M.plot()\n",
    "M.plotx(qs,v)\n",
    "plt.show()\n",
    "(ts,qps) = M.Hamiltonian_dynamicsf(q,p)\n",
    "ps = qps[:,1,:]\n",
    "print(\"Energy: \",np.array([M.Hf(q,p) for (q,p) in zip(qs,ps)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Visualize bridge\n",
    "\n",
    "# Brownian motion\n",
    "from src.stochastics import Brownian_coords\n",
    "Brownian_coords.initialize(M)\n",
    "# Delyon/Hu guided process\n",
    "from src.stochastics.guided_process import *\n",
    "\n",
    "Cholesky = T.slinalg.Cholesky()\n",
    "phi = lambda q,v: T.tensordot(T.nlinalg.MatrixInverse()(Cholesky(M.gsharp(q))),-(q-v).flatten(),(1,0))\n",
    "sde_Brownian_coords_guided = get_sde_guided(M.sde_Brownian_coords,phi,lambda q: Cholesky(M.gsharp(q)))\n",
    "Brownian_coords_guided = lambda q,v,dWt: integrate_sde(sde_Brownian_coords_guided,\n",
    "                                                   integrator_ito,\n",
    "                                                   q,dWt,T.constant(0.),T.constant(0.),v)\n",
    "q0 = M.element()\n",
    "v = M.element()\n",
    "Brownian_coords_guidedf = theano.function([q0,v,dWt], Brownian_coords_guided(q0,v,dWt)[:4])\n",
    "phif = theano.function([q0,v], phi(q0,v))\n",
    "\n",
    "# derivatives\n",
    "thetas = (q0,M.k_alpha,M.k_sigma) # parameters\n",
    "def dlog_likelihood(q,v,dWt):\n",
    "    s = Brownian_coords_guided(q,v,dWt)\n",
    "    dlog_likelihoods = tuple(T.grad(s[2][-1],theta) for theta in thetas)\n",
    "    \n",
    "    return (s[0],s[1],s[2],s[3])+dlog_likelihoods\n",
    "dlog_likelihoodf = theano.function([q0,v,dWt],dlog_likelihood(q0,v,dWt))\n",
    "v = np.stack((np.linspace(-.5,.5,M.N.eval()),np.ones(M.N.eval()))).T.flatten()\n",
    "(ts,qs,log_likelihood,log_varphi) = Brownian_coords_guidedf(q,v,dWsf(M.dim.eval()))\n",
    "print(\"log likelihood: \", log_likelihood[-1], \", log varphi: \", log_varphi[-1])\n",
    "M.plot()\n",
    "M.plotx(np.vstack((q,qs)),curve=True)\n",
    "M.plotx(v,color='k',curve=True)\n",
    "# plt.savefig('bridge.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set up for inference example\n",
    "\n",
    "# initialize\n",
    "N.set_value(10)\n",
    "k_alpha.set_value(.01)\n",
    "n_steps.set_value(20)\n",
    "\n",
    "# setup \n",
    "x0 = ellipse([0.,0.],[1.,.5])\n",
    "q0 = x0.flatten()\n",
    "v0 = np.vstack((np.zeros(N.eval()),np.ones(N.eval()))).T\n",
    "print(\"q = \", q0)\n",
    "\n",
    "avg_landmark_dist = np.mean(np.linalg.norm(x0[:-1]-x0[1:],axis=1))\n",
    "k_sigma.set_value(avg_landmark_dist*np.diag((1.,1.)))\n",
    "print(\"k_alpha: \", k_alpha.eval(), \", k_sigma: \", k_sigma.eval().flatten())\n",
    "k_alpha_init = k_alpha.eval()\n",
    "k_sigma_init = k_sigma.eval()\n",
    "\n",
    "plotx(q0,curve=True,color='k')\n",
    "v0 = np.vstack((np.zeros(N.eval()),np.ones(N.eval()))).T\n",
    "p0 = gMflatf(q0,v0.flatten())\n",
    "plotx(Expf(q0,p0),curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample for Brownian motion transition distribution\n",
    "N_samples = 64\n",
    "obss = np.zeros((N_samples,)+q0.shape)\n",
    "qsvs = np.zeros((N_samples,n_steps.eval(),)+q0.shape)\n",
    "# srng.seed(422)\n",
    "for i in range(N_samples):\n",
    "    (ts,qsv) = Brownian_coordsf(q0,dWsf())\n",
    "    qsvs[i] = qsv\n",
    "    obss[i] = qsv[-1]\n",
    "\n",
    "# plot samples\n",
    "plot_samples = 15\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, plot_samples)]\n",
    "for i in range(plot_samples):\n",
    "    plotx(obss[i],curve=True,color=colors[i])\n",
    "plt.axis('equal')\n",
    "# plt.savefig('samples.pdf')\n",
    "plt.show()\n",
    "\n",
    "# plot samples with paths\n",
    "plot_samples = 5\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, plot_samples)]\n",
    "plotx(q0,color='k',curve=True)\n",
    "for i in range(plot_samples):\n",
    "    plotx(qsvs[i],color=colors[i],curve=True)\n",
    "# plt.savefig('samples_paths.pdf')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.mle import *\n",
    "import src.mle as mle\n",
    "mle.dlog_likelihoodf = dlog_likelihoodf\n",
    "mle.thetas = thetas\n",
    "\n",
    "options = {}\n",
    "options['samples_per_obs'] = 1\n",
    "options['epochs'] = 80\n",
    "options['learning_rate'] = .5e-3#1.5e-3\n",
    "options['varphi_update_rate'] = 1.\n",
    "options['initial'] = (np.zeros(d.eval()),\n",
    "                      .12,.3*np.diag((1.,1.)))#.2,.6*np.diag((1.,1.)))\n",
    "options['update_v'] = lambda g: g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# produce bridge plot for paper\n",
    "\n",
    "def bridge_sampling(lg,dWsf,options,pars):\n",
    "    (v,log_phi,seed) = pars\n",
    "    if seed:\n",
    "        srng.seed(seed)\n",
    "    bridges = np.zeros((options['samples_per_obs'],n_steps.eval(),)+lg.shape)\n",
    "    log_varphis = np.zeros((options['samples_per_obs'],))\n",
    "    log_likelihoods = np.zeros((options['samples_per_obs'],))\n",
    "    dlog_likelihoods = None#tuple(np.zeros((options['samples_per_obs'],)+theta.shape) for theta in thetas)\n",
    "    #global dlog_likelihoodf\n",
    "    for i in range(options['samples_per_obs']):\n",
    "        (ts,gsv,log_likelihood,log_varphi,*dlog_likelihood) = dlog_likelihoodf(lg,v,dWsf())\n",
    "        print(log_varphi)\n",
    "        bridges[i] = gsv\n",
    "        log_varphis[i] = log_varphi[-1]\n",
    "        #log_likelihoods[i] = log_likelihood[-1]\n",
    "        #for (j,dl) in enumerate(dlog_likelihoods):\n",
    "         #   dl[i] = dlog_likelihood[i]\n",
    "        try:\n",
    "            v = options['update_v'](v) # update v, e.g. simulate in fiber\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return (bridges,log_varphis,log_likelihoods,dlog_likelihoods,v)\n",
    "# bridge(g0,A.eval(),options,(v.eval(),np.random.randint(1000)))[0].shape\n",
    "\n",
    "def lbridge_sampling(thetas,*args,**kwargs):\n",
    "    k_alpha.set_value(thetas[1])\n",
    "    k_sigma.set_value(thetas[2])\n",
    "    return bridge_sampling(q0,*args,**kwargs)\n",
    "\n",
    "N_samples = 1\n",
    "tmp0 = options['samples_per_obs']\n",
    "options['samples_per_obs'] = 1\n",
    "tmp1 = k_alpha.eval()\n",
    "k_alpha.set_value(.01)\n",
    "v = obss[0]\n",
    "log_phis = np.zeros((N_samples,))\n",
    "try:\n",
    "    mpu.openPool()\n",
    "    sol = mpu.pool.imap(partial(lbridge_sampling,options['initial'],dWsf,options),\\\n",
    "                        mpu.inputArgs(v.reshape((1,)+v.shape),log_phis,np.random.randint(1000,size=N_samples)))\n",
    "    res = list(sol)\n",
    "    bridges = mpu.getRes(res,0)\n",
    "    log_varphis = mpu.getRes(res,1)\n",
    "    log_likelihoods = mpu.getRes(res,2)\n",
    "    dlog_likelihoods = mpu.getRes(res,3)\n",
    "except:\n",
    "    mpu.closePool()\n",
    "    raise\n",
    "else:\n",
    "    mpu.closePool()\n",
    "\n",
    "# plot\n",
    "colormap = plt.get_cmap('winter')\n",
    "colors=[colormap(k) for k in np.linspace(0, 1, options['samples_per_obs'])]\n",
    "for j in range(bridges.shape[1]):\n",
    "    gsv = np.vstack((q0.flatten(),bridges[0,j]))\n",
    "    plotx(gsv,linewidth=.6,color=colors[j],curve=True)\n",
    "plotx(v,color='b',curve=True)        \n",
    "plotx(q0,color='k',curve=True)\n",
    "# plt.savefig('bridges.pdf')\n",
    "\n",
    "options['samples_per_obs'] = tmp0\n",
    "k_alpha.set_value(tmp1)\n",
    "N_samples = obss.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transition density\n",
    "\n",
    "t = T.scalar()\n",
    "sde_Brownian_coordsf = theano.function([t,q],sde_Brownian_coords(dWs[0],t,q),on_unused_input='ignore')\n",
    "\n",
    "# symbolic lift to fiber not supported yet\n",
    "def log_p_T(g,v,dWs,bridge_sde,phi,options,sigma=None,sde=None):\n",
    "    if sde is not None:\n",
    "        (_,_,XT) = sde(dWs,Tend,v) # starting point of SDE, we need diffusion field X at t=0\n",
    "        sigma = XT\n",
    "    assert(sigma is not None)\n",
    "    Cgv = T.sum(phi(g,v)**2)    \n",
    "\n",
    "    # sample noise\n",
    "    (cout, updates) = theano.scan(fn=lambda x: dWs,\n",
    "            outputs_info=[T.zeros_like(dWs)],\n",
    "            n_steps=options['samples_per_obs'])\n",
    "    dWsi = cout\n",
    "    \n",
    "    # bridges\n",
    "    def bridge_p_T(dWs,gsv,log_varphi):\n",
    "        (ts,gsv,log_likelihood,log_varphi,_) = bridge_sde(g,v,dWs)\n",
    "        return (gsv,log_varphi[-1])\n",
    "    \n",
    "    (cout, updates) = theano.scan(fn=bridge_p_T,\n",
    "            outputs_info=[T.zeros((n_steps,d)),T.constant(0.)],\n",
    "            sequences=[dWsi])\n",
    "    bridges = cout[:][0]\n",
    "    log_varphis = cout[:][1]\n",
    "\n",
    "#     p_T =  T.power(2.*np.pi*Tend,-.5*sigma.shape[0])/T.abs_(T.nlinalg.Det()(sigma))*T.exp(-Cgv/(2.*Tend))*T.mean(T.exp(log_varphis))\n",
    "    return -.5*sigma.shape[0]*T.log(2.*np.pi*Tend)-linalg.LogAbsDet()(sigma)-Cgv/(2.*Tend)+T.log(T.mean(T.exp(log_varphis)))\n",
    "v = T.vector()\n",
    "log_p_Tf = theano.function([q,v],log_p_T(q,v,dWs,Brownian_coords_guided,phi,options,sde=sde_Brownian_coords))\n",
    "def dlog_p_T(*args,**kwargs):\n",
    "    llog_p_T = log_p_T(*args,**kwargs)\n",
    "    return (llog_p_T,)+tuple(T.grad(llog_p_T,theta) for theta in thetas)\n",
    "dlog_p_Tf = theano.function([q,v],dlog_p_T(q,v,dWs,Brownian_coords_guided,phi,options,sde=sde_Brownian_coords))\n",
    "p_Tf = theano.function([q,v],T.exp(log_p_T(q,v,dWs,Brownian_coords_guided,phi,options,sde=sde_Brownian_coords)))\n",
    "v = Expf(q0,p0)\n",
    "print(log_p_Tf(q0,v))\n",
    "print(p_Tf(q0,v))\n",
    "print(dlog_p_Tf(q0,v))\n",
    "\n",
    "def log_p_T_numeric(lg,v,dWsf,bridge_sdef,phif,options,sigma=None,sdef=None,x0=None):\n",
    "    vorg = v # debug\n",
    "    if x0 is not None: # if lv point on manifold, lift target to fiber\n",
    "        v = lift_to_fiber(v,x0)[0]\n",
    "    if sdef is not None:\n",
    "        (_,_,XT) = sdef(Tend.eval(),v) # starting point of SDE, we need diffusion field X at t=0\n",
    "        sigma = XT\n",
    "    elif sigma is not None:\n",
    "        sigma = sigma.eval()\n",
    "    assert(sigma is not None)\n",
    "    bridges = np.zeros((options['samples_per_obs'],n_steps.eval(),)+lg.shape)\n",
    "    log_varphis = np.zeros((options['samples_per_obs'],))\n",
    "    Cgvs = np.zeros((options['samples_per_obs'],))\n",
    "    for i in range(options['samples_per_obs']):\n",
    "        try:\n",
    "            (ts,gsv,log_likelihood,log_varphi) = bridge_sdef(lg,v,dWsf())\n",
    "        except ValueError:\n",
    "            print('Bridge sampling error:')\n",
    "            print(v)\n",
    "            print(vorg)\n",
    "            print(lift_to_fiber(vorg,x0))\n",
    "            print(phif(lg,v))\n",
    "            raise\n",
    "        bridges[i] = gsv\n",
    "        log_varphis[i] = log_varphi[-1]\n",
    "        Cgvs[i] = np.linalg.norm(phif(lg,v))**2\n",
    "        try:\n",
    "            v = options['update_v'](v) # update v, e.g. simulate in fiber\n",
    "        except KeyError:\n",
    "            pass\n",
    "#     p_T = np.power(2.*np.pi*Tend.eval(),-.5*sigma.shape[0])/np.abs(np.linalg.det(sigma))*np.mean(np.exp(-Cgvs/(2.*Tend.eval()))*np.exp(log_varphis))\n",
    "    return -.5*sigma.shape[0]*np.log(2.*np.pi*Tend.eval())-np.log(np.abs(np.linalg.det(sigma)))+np.log(np.mean(np.exp(-Cgvs/(2.*Tend.eval()))*np.exp(log_varphis)))\n",
    "p_T_numeric = lambda *pars, **kwargs: np.exp(log_p_T_numeric(*pars,**kwargs))\n",
    "\n",
    "print(log_p_T_numeric(q0,v,dWsf,Brownian_coords_guidedf,phif,{'samples_per_obs': 1},sdef=sde_Brownian_coordsf))\n",
    "print(p_T_numeric(q0,v,dWsf,Brownian_coords_guidedf,phif,{'samples_per_obs': 1},sdef=sde_Brownian_coordsf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vs = obss\n",
    "try:\n",
    "    def llog_p_T(thetas,pars):\n",
    "        (v,seed) = pars\n",
    "        if seed:\n",
    "            srng.seed(seed)\n",
    "        k_alpha.set_value(thetas[1])\n",
    "        k_sigma.set_value(thetas[2])\n",
    "        return dlog_p_Tf(q0,v)\n",
    "    \n",
    "    log_likelihoods = np.zeros(options['epochs'])\n",
    "    \n",
    "    # initial thetas\n",
    "    q0 = np.mean(obss,axis=0)\n",
    "    k_alpha.set_value(options['initial'][1])    \n",
    "#     avg_landmark_dist = np.mean(np.linalg.norm(q0.reshape((-1,m.eval()))[:-1]-q0.reshape((-1,m.eval()))[1:],axis=1))\n",
    "#     k_sigma.set_value(avg_landmark_dist*np.diag((1.,1.)))\n",
    "    k_sigma.set_value(options['initial'][2])\n",
    "    print(\"initial thetas\",\n",
    "          \"\\n\\tq0: \", q0, \", \\n\\tk_alpha: \", k_alpha.eval(), \", \\n\\tk_sigma: \", k_sigma.eval().flatten())    \n",
    "    \n",
    "    # for plotting iterations\n",
    "    q0s = np.zeros((options['epochs'],)+q0.shape)    \n",
    "    k_alphas = np.zeros((options['epochs'],)+k_alpha.eval().shape)    \n",
    "    k_sigmas = np.zeros((options['epochs'],)+k_sigma.eval().shape)    \n",
    "    mpu.openPool()\n",
    "    for i in range(options['epochs']):\n",
    "        sol = mpu.pool.imap(partial(llog_p_T,(q0,k_alpha.eval(),k_sigma.eval())),\\\n",
    "                            mpu.inputArgs(vs,np.random.randint(1000,size=N_samples)))\n",
    "        res = list(sol)\n",
    "        log_likelihood = np.mean(mpu.getRes(res,0),axis=0)\n",
    "        dqlog_likelihood = np.mean(mpu.getRes(res,1),axis=0)\n",
    "        dk_alphalog_likelihood = np.mean(mpu.getRes(res,2),axis=0)\n",
    "        dk_sigmalog_likelihood = np.mean(mpu.getRes(res,3),axis=0)\n",
    "        \n",
    "        log_likelihoods[i] = log_likelihood # total log likelihood        \n",
    "\n",
    "        # step, update parameters and varphis                            \n",
    "        q0 = q0+options['learning_rate']*np.dot(gMsharpf(q0),dqlog_likelihood) # use Riemannian g-gradient\n",
    "        q0s[i] = q0\n",
    "        k_alpha.set_value(k_alpha.eval()+options['learning_rate']/d.eval()*dk_alphalog_likelihood)\n",
    "        k_alphas[i] = k_alpha.eval()\n",
    "        k_sigma.set_value(k_sigma.eval()+options['learning_rate']*dk_sigmalog_likelihood)\n",
    "        k_sigmas[i] = k_sigma.eval()\n",
    "        \n",
    "        print(\"iteration: \", i, \", log-likelihood: \", log_likelihood, \n",
    "              \", new thetas: \\n\\tq0: \", q0, \", \\n\\tk_alpha: \", k_alpha.eval(), \", \\n\\tk_sigma: \", k_sigma.eval().flatten())        \n",
    "except:\n",
    "    mpu.closePool()\n",
    "    raise\n",
    "else:\n",
    "    mpu.closePool()\n",
    "\n",
    "## plot\n",
    "plt.plot(range(options['epochs']),log_likelihoods)\n",
    "# plt.savefig('likeliood.pdf')\n",
    "plt.show()\n",
    "plt.plot(range(options['epochs']),q0s.reshape((q0s.shape[0],-1)))\n",
    "# plt.savefig('q0s.pdf')\n",
    "plt.show()\n",
    "plt.plot(range(options['epochs']),k_alphas,color='b')\n",
    "plt.hlines(k_alpha_init,plt.xlim()[0],plt.xlim()[1],color='r')\n",
    "# plt.savefig('k_alpha.pdf')\n",
    "plt.show()\n",
    "plt.plot(range(options['epochs']),k_sigmas.reshape((k_sigmas.shape[0],-1)),color='b')\n",
    "plt.hlines(k_sigma_init.flatten(),plt.xlim()[0],plt.xlim()[1],color='r')\n",
    "plt.ylabel(r'$\\sigma$', fontsize=30)\n",
    "# plt.savefig('k_sigma.pdf')\n",
    "plt.show()\n",
    "plotx(x0.flatten(),color='k',curve=True)\n",
    "plotx(q0,color='b',curve=True)\n",
    "# plt.savefig('est_q0.pdf')\n",
    "plt.show()\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(range(options['epochs']),log_likelihoods,'g--')\n",
    "ax1.set_ylabel(r'$\\mathcal{L}_\\theta$', fontsize=30)\n",
    "ax2.plot(range(options['epochs']),k_alphas,color='b')\n",
    "ax2.hlines(k_alpha_init,plt.xlim()[0],plt.xlim()[1],color='r')\n",
    "ax2.set_ylabel(r'$\\alpha$', fontsize=30)\n",
    "# plt.savefig('likelihood-k_alpha.pdf')\n",
    "plt.show()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample with estimated parameters\n",
    "obss_new = np.zeros((N_samples,)+q0.shape)\n",
    "for i in range(N_samples):\n",
    "    (ts,qsv) = Brownian_coordsf(q0,dWsf())\n",
    "    qsvs[i] = qsv\n",
    "    obss_new[i] = qsv[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "def estimate_qq(data_q):\n",
    "    data_mean= data_q.sum(0)/data_q.shape[0]\n",
    "    data= data_q - data_mean\n",
    "    \n",
    "    return [data_mean,(data[:,:,:,np.newaxis,np.newaxis]*data[:,np.newaxis,np.newaxis,:,:]).sum(0)/data.shape[0]]\n",
    "qq = estimate_qq(obss.reshape((-1,N.eval(),m.eval())))\n",
    "qq_new = estimate_qq(obss_new.reshape((-1,N.eval(),m.eval())))\n",
    "\n",
    "#plot density distribution of landmarks\n",
    "def plot_distribution(xss):\n",
    "\n",
    "    xTx=[]\n",
    "    xTy=[]\n",
    "    for i in range(xss.shape[0]):\n",
    "        for j in range(0,N.eval()):\n",
    "            xTx.append(xss[i,j,0])\n",
    "            xTy.append(xss[i,j,1])\n",
    "    hist,histy,histx= np.histogram2d(xTy,xTx,bins=25)\n",
    "    extent = [histx[0],histx[-1],histy[0],histy[-1]]\n",
    "\n",
    "    \n",
    "    #plt.contour(hist/np.max(hist),extent=extent,levels=[0.05,0.2,0.4,0.6],zorder=10)\n",
    "    plt.imshow(hist/np.max(hist),extent=extent,interpolation='bicubic',origin='lower',cmap='Greys')#,levels=[0.05,0.2,0.4,0.6],zorder=10)\n",
    "    #plt.colorbar()\n",
    "\n",
    "# plot variance\n",
    "def plot_final_ellipses(q,QQ,coeff=1.,c='m',ls='-',lw=1):\n",
    "    # plot sigma as ellipses \n",
    "    from matplotlib.patches import Ellipse\n",
    "    from numpy import linalg as LA\n",
    "    ax= plt.gca()\n",
    "    for i in range(N.eval()):\n",
    "        qq_eig,qq_vec = LA.eig(QQ[i,:,i,:])\n",
    "        qq_eig = np.sqrt(qq_eig)\n",
    "        theta = np.degrees(np.arctan(qq_vec[1,0]/qq_vec[0,0]))\n",
    "\n",
    "        ell= Ellipse(xy=q[i] ,width=coeff*qq_eig[0],height= coeff*qq_eig[1],angle=theta,ls=ls,lw=lw)\n",
    "        ax.add_artist(ell)\n",
    "        ell.set_alpha(1.)\n",
    "        ell.set_facecolor('None')\n",
    "        ell.set_edgecolor(c)\n",
    "        \n",
    "plotx(x0.flatten(),color='k',curve=True)\n",
    "plotx(q0,color='b',curve=True)\n",
    "plot_final_ellipses(qq[0],qq[1],coeff=3.,c='k',ls='-',lw=2)\n",
    "plot_final_ellipses(q0.reshape((-1,m.eval())),qq_new[1],coeff=3.,c='b',ls='--',lw=2)\n",
    "plot_distribution(obss_new.reshape((-1,N.eval(),m.eval())))\n",
    "# plt.savefig('ellipse_inf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
