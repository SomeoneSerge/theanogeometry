{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # This file is part of Theano Geometry\n",
    "#\n",
    "# Copyright (C) 2017, Stefan Sommer (sommer@di.ku.dk)\n",
    "# https://bitbucket.org/stefansommer/theanogemetry\n",
    "#\n",
    "# Theano Geometry is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# Theano Geometry is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with Theano Geometry. If not, see <http://www.gnu.org/licenses/>.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.params as params\n",
    "params.manifold = 'landmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manifold import *\n",
    "from src.metric import *\n",
    "from src.Stochastic_Development import *\n",
    "\n",
    "from src.plotting import *\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 7, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression dynamics\n",
    "from src.Regression.params import *\n",
    "from src.Regression.Processes import *\n",
    "from src.Regression.MM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.set_value(1)\n",
    "m.set_value(1)\n",
    "rank.set_value(1)\n",
    "n_samples.set_value(50)\n",
    "#n_sim.set_value(10)\n",
    "\n",
    "# True Parameters:\n",
    "y0 = np.array([-1,0,0,0,1,0]).reshape((3,2))[0:N.eval(),:].flatten()\n",
    "W0 = np.array([[2,0.1],[0.1,2]])[0:m.eval(),0:m.eval()]\n",
    "drift0 = np.array([1,2])[0:m.eval()]\n",
    "tau0 = 0.5\n",
    "ui0 = np.array([[0,1],[1,0],[0,1],[1,0],[0,1],[1,0]])[0:d.eval(),0:m.eval()]\n",
    "para0 = np.hstack((tau0,drift0,W0.flatten(),y0,ui0.flatten()))\n",
    "\n",
    "q0 = np.hstack([y0.flatten(),ui0.flatten()]).astype(theano.config.floatX)\n",
    "print(\"q0 = \", q0)\n",
    "\n",
    "x00 = np.array([0,0])[0:m.eval()]\n",
    "xT0 = np.random.normal(0, 6, (n_samples.get_value(),m.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test processes:\n",
    "yT = np.zeros((n_samples.get_value(),d.eval()))\n",
    "for i in range(n_samples.get_value()):\n",
    "    dwt0 = np.random.normal(0, np.sqrt(dt.eval()), (n_steps.get_value(),m.get_value()))\n",
    "    Xt = BrownBridgef(dwt0.flatten(),x00,xT0[i,:])\n",
    "    Zt = RegProcf(Xt.flatten(),x00,W0,drift0)\n",
    "    Ut = stoc_devf(q0,Zt[1],drift0)\n",
    "\n",
    "    #plotFMx(Ut,N_vec=0)\n",
    "    yT[i,:] = Ut[-1,0:d.eval()] + np.random.normal(0, tau0, (1,d.eval()))\n",
    "    plt.plot(yT[i,0], yT[i,1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method of Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pred(para,xT,x0,y):\n",
    "    \n",
    "    tau = para[0]\n",
    "    dwt = rng.normal(size = (n_samples,n_steps,m), avg = 0, std = T.sqrt(dt))\n",
    "    (cout, updates) = theano.scan(fn=Predi,\n",
    "                                  sequences=[xT,dwt],\n",
    "                                  non_sequences=[x0,para],\n",
    "                                  n_steps=n_samples)\n",
    "    \n",
    "    M1 = 1./2*T.mean(y - cout, axis = 0)**2\n",
    "    M2 = 1./2*(1./n_samples*T.dot(xT.T,(y-cout)).flatten())**2\n",
    "    #M2 = 1./2*T.mean(xT.reshape((n_samples,m))*(y - cout), axis = 0)**2\n",
    "    M3 = 1./2*(1./(y.shape[0]-2)*T.sum((y - cout)**2, axis = 0) - tau**2)**2\n",
    "    \n",
    "    return 1./M1.shape[0]*T.sum(M1) + 1./M2.shape[0]*T.sum(M2) + 1./M3.shape[0]*T.sum(M3)\n",
    "\n",
    "para = T.vector()\n",
    "y = T.matrix()\n",
    "x0 = T.vector()\n",
    "xT = T.matrix()\n",
    "Predf = theano.function([para,xT,x0,y], Pred(para,xT,x0,y),\n",
    "                       on_unused_input='ignore')\n",
    "\n",
    "#gradP = lambda para,xT,x0,y: T.grad(Pred(para,xT,x0,y),para)\n",
    "#gradPf = theano.function([para,xT,x0,y], gradP(para,xT,x0,y))\n",
    "\n",
    "#n_sim = theano.shared(20)\n",
    "#def fopt(para,y,x0,xT,pred0,b):\n",
    "#    \n",
    "#    n_sim1 = ifelse(T.eq(b,0), 10, n_sim)\n",
    "#    \n",
    "#    dwt = rng.normal(size = (n_sim1,n_samples,n_steps,m), avg = 0, std = T.sqrt(dt))\n",
    "#    \n",
    "#    (cout, updates) = theano.scan(fn=Pred,\n",
    "#                                 sequences=[dwt],\n",
    "#                                 non_sequences=[xT,x0,para,y],\n",
    "#                                 n_steps=n_sim1)\n",
    "#    \n",
    "#    pred1 = ifelse(T.eq(b,0), T.concatenate([cout,pred0[0:n_sim-10]]),\n",
    "#                   cout)\n",
    "#    \n",
    "#    return 1./pred1.shape[0]*T.sum(pred1), pred1\n",
    "\n",
    "#b = T.scalar()\n",
    "#pred0 = T.vector()\n",
    "#foptf = theano.function([para,y,x0,xT,pred0,b], fopt(para,y,x0,xT,pred0,b),\n",
    "#                       on_unused_input='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = theano.shared(10)\n",
    "def fopt(para,xT,x0,y):\n",
    "    \n",
    "    #n_sim1 = ifelse(T.eq(b,0), 10, n_sim)\n",
    "    \n",
    "    #dwt = rng.normal(size = (n_sim,n_samples,n_steps,m), avg = 0, std = T.sqrt(dt))\n",
    "    \n",
    "    (cout, updates) = theano.scan(fn=Pred,\n",
    "                                 #sequences=[dwt],\n",
    "                                 non_sequences=[para,xT,x0,y],\n",
    "                                 n_steps=n_sim)\n",
    "    \n",
    "    #pred1 = ifelse(T.eq(b,0), T.concatenate([cout,pred0[0:n_sim-10]]),\n",
    "    #               cout)\n",
    "    \n",
    "    return 1./cout.shape[0]*T.sum(cout), cout\n",
    "\n",
    "#from multiprocess import Pool\n",
    "#import src.multiprocess_utils as mpu\n",
    "#import itertools\n",
    "#from functools import partial\n",
    "#def multPred(para,start,y2,end2):\n",
    "#    \n",
    "#    p = Pool(processes = 2)\n",
    "#    #mpu.openPool()\n",
    "#    sol = p.imap(partial(Predf,para,xT,x0,y),\n",
    "#                         chunksize = n_sim/2)\n",
    "#    res = list(sol)\n",
    "#    p.terminate()\n",
    "#    #mpu.closePool()\n",
    "#\n",
    "#    return np.array(zip(res))#[:,0,:]\n",
    "\n",
    "#b = T.scalar()\n",
    "#pred0 = T.vector()\n",
    "foptf = theano.function([para,xT,x0,y], fopt(para,xT,x0,y),\n",
    "                        on_unused_input='ignore')\n",
    "\n",
    "gradPi = lambda para,xT,x0,y: T.grad(Pred(para,xT,x0,y),para)\n",
    "gradPif = theano.function([para,xT,x0,y], gradPi(para,xT,x0,y))\n",
    "\n",
    "def gradP(para,xT,x0,y):\n",
    "    \n",
    "    (cout, updates) = theano.scan(fn=gradPi,\n",
    "                                 #sequences=[dwt],\n",
    "                                 non_sequences=[para,xT,x0,y],\n",
    "                                 n_steps=n_sim)\n",
    "    \n",
    "    return 1./cout.shape[0]*T.sum(cout, axis = 0)\n",
    "gradPf = theano.function([para,xT,x0,y], gradP(para,xT,x0,y))\n",
    "\n",
    "#def multgrad(para,start,y2,end2):\n",
    "#    \n",
    "#    p = Pool(processes = 2)\n",
    "#    #mpu.openPool()\n",
    "#    sol = p.imap(partial(gradPif,para,xT,x0,y),\n",
    "#                         chunksize = n_sim/2)\n",
    "#    res = list(sol)\n",
    "#    p.terminate()\n",
    "#    #mpu.closePool()\n",
    "#\n",
    "#    return np.array(zip(res))#[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraIp = para0.copy()\n",
    "paraIp[1] = 1.3\n",
    "start = time.time()\n",
    "#for i in range(10):\n",
    "print(\"Sum of Moments = \",foptf(paraIp,xT0,x00,yT)[0])\n",
    "diff = time.time() - start\n",
    "print(\"time = \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraIp = para0.copy()\n",
    "paraIp[1] = 1.3\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    print(\"Sum of Moments = \",Predf(paraIp,xT0,x00,yT))\n",
    "diff = time.time() - start\n",
    "print(\"time = \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    \n",
    "    para = np.hstack((para0[0],w,para0[2:]))\n",
    "    return Predf(para,xT0,x00,yT)#, gradPif(para,xT0,x00,yT)[2]\n",
    "\n",
    "w0 = np.linspace(0,2,20)\n",
    "for j in range(2):\n",
    "    start = time.time()\n",
    "    fv = np.zeros_like(w0)\n",
    "    for i in range(w0.shape[0]):\n",
    "        start = time.time()\n",
    "        fv[i] = f(w0[i])\n",
    "        print(\"w = \", w0[i], \": time = \", time.time() - start)#, \", grad norm = \", np.linalg.norm(f(w0[i])[1]))\n",
    "    print(\"wmin = \",w0[np.where(fv == fv.min())], \n",
    "          \" : time = \", time.time()-start)\n",
    "    plt.plot(w0,fv)\n",
    "    minw0 = w0[np.where(fv == fv.min())]\n",
    "    plt.plot(np.array([minw0,minw0]),np.array([0,max(fv)]), 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    \n",
    "    para = np.hstack((para0[0],w,para0[2:]))\n",
    "    return foptf(para,xT0,x00,yT)#, gradPf(para,xT0,x00,yT)[2]\n",
    "\n",
    "w0 = np.linspace(0,2,20)\n",
    "for j in range(2):\n",
    "    start = time.time()\n",
    "    fv = np.zeros_like(w0)\n",
    "    for i in range(w0.shape[0]):\n",
    "        start = time.time()\n",
    "        fv[i] = f(w0[i])[0]\n",
    "        print(\"w = \", w0[i], \": time = \", time.time() - start)#, \", grad norm = \", np.linalg.norm(f(w0[i])[1]))\n",
    "    print(\"wmin = \",w0[np.where(fv == fv.min())], \n",
    "          \" : time = \", time.time()-start)\n",
    "    plt.plot(w0,fv)\n",
    "    minw0 = w0[np.where(fv == fv.min())]\n",
    "    plt.plot(np.array([minw0,minw0]),np.array([0,max(fv)]), 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(\"Gradient = \",gradPf(para0,xT0,x00,yT))\n",
    "diff = time.time() - start\n",
    "print(\"time = \", diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Optimization(init,tol,maxIter,gamma,y,x0,xT,k,norm):\n",
    "    \n",
    "    paraN = init.copy() #np.zeros((init.shape[0]))\n",
    "    para1 = init.copy()\n",
    "    opt1 = foptf(para1,xT,x0,y)[0]\n",
    "    v0 = 0\n",
    "    Avpara1 = np.zeros((k.shape[0]))\n",
    "    av = np.zeros((k.shape[0]))\n",
    "    t = 0\n",
    "    \n",
    "    for i in range(0,maxIter):\n",
    "        \n",
    "        #paraN = para1.copy()\n",
    "        print(\"i = \", i)\n",
    "\n",
    "        start1 = time.time()\n",
    "        grad = gradPf(para1,xT,x0,y)\n",
    "        diff1 = time.time() - start1\n",
    "        #print(\"time = \", diff1)\n",
    "        print(\"time = \", diff1, \": grad = \",np.round(grad[k]/np.linalg.norm(grad[k]),4))\n",
    "        \n",
    "        alpha = 1./(np.sqrt(i) + 1)\n",
    "        if i == 0:\n",
    "            alpha = 1.\n",
    "        print(\"alpha = \",alpha, \", gamma = \", gamma)\n",
    "\n",
    "        vt = alpha*gamma*grad[k]/np.linalg.norm(grad[k]) #+ 0.4*v0\n",
    "        paraN[k] = para1[k] - vt #alpha*gamma*grad[k]/np.linalg.norm(grad[k])\n",
    "        \n",
    "        #v0 = vt.copy()\n",
    "        \n",
    "        # Averaging scheme:\n",
    "        #eta = 3\n",
    "        #if i > maxIter/4:\n",
    "        #    av = Avpara1 + paraN[k]\n",
    "        #    t = t + 1\n",
    "        #    paraN[k] = 1./t*av\n",
    "        #    #paraN[k] = (1-(eta+1)/(i+eta))*Avpara1[k] + (eta+1)/(i+eta)*paraN[k]\n",
    "        #    Avpara1[k] = av\n",
    "\n",
    "        opt2 = foptf(paraN,xT,x0,y)[0]\n",
    "        diffp = np.dot(paraN[k] - para1[k],paraN[k] - para1[k])\n",
    "        print(\"funcval = \", opt2, \": Diff parameters = \", diffp, \", Grad norm = \", np.linalg.norm(grad[k]))\n",
    "        \n",
    "        if opt2 <= 5*opt1:\n",
    "            if diffp < tol:\n",
    "                print(\"Final para =\", paraN[k])\n",
    "                print(\"i break = \", i, \": Converged\")\n",
    "                break\n",
    "             \n",
    "            print('para = ',np.round(paraN[k],4))\n",
    "            para1 = paraN.copy()\n",
    "            opt1 = opt2\n",
    "        if opt2 > 5*opt1:\n",
    "            gamma = 2.*gamma/3\n",
    "            print(\"OBS!! Gamma halved = \", gamma)\n",
    "        \n",
    "        if np.linalg.norm(grad[k]) < tol:\n",
    "            print(\"grad small - converged\")\n",
    "            break\n",
    "        \n",
    "    if i == (maxIter-1):\n",
    "        print(\"Maxiterations reached\")\n",
    "        \n",
    "    return np.round(paraN,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k0 = 3\n",
    "paraIp = para0.copy()\n",
    "\n",
    "paraOpI = np.hstack([2,range(5,7)])\n",
    "#paraOp1 = np.hstack([2])\n",
    "\n",
    "paraIp[paraOpI] = para0[paraOpI] + 0.8\n",
    "print(para0)\n",
    "print(paraIp)\n",
    "print(paraOpI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(\"Gradient = \",gradPf(paraIp,xT0,x00,yT)[paraOpI])\n",
    "diff = time.time() - start\n",
    "print(\"time = \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma0 = np.array([1,1,1])#np.array([1,1,1]) #*np.array([100,100,100,10,10,10,10,100,100,10,10,10,1])\n",
    "res0 = Optimization(paraIp,10**(-5),50,gamma0,yT,x00,\n",
    "                    xT0,paraOpI,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paraIp = para0 + 0.8\n",
    "paraIp[paraOpI] = res0[paraOpI]\n",
    "print(\"True = \", para0)\n",
    "print(\"Initial = \", paraIp)\n",
    "paraOpI = np.hstack([range(0,3)])\n",
    "print(paraOpI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gradfoo = gradPf(paraIp,xT0,x00,yT)\n",
    "print(\"Gradient = \",gradfoo[paraOpI])\n",
    "diff = time.time() - start\n",
    "print(\"time = \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma0 = np.array([0.1,0.1,0.01]) #*np.array([100,100,100,10,10,10,10,100,100,10,10,10,1])\n",
    "res0 = Optimization(paraIp,10**(-5),20,gamma0,yT,x00,\n",
    "                    xT0,paraOpI,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient free optimization CMAES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invMat(A):\n",
    "    return T.nlinalg.matrix_inverse(A)\n",
    "A = T.matrix()\n",
    "invMatf = theano.function([A], invMat(A))\n",
    "\n",
    "def f(para):\n",
    "    \n",
    "    paraf[0:3] = para\n",
    "    return foptf(paraf,xT0,x00,yT)[0]\n",
    "\n",
    "def fprov(maxIter,L,mu,sigma,m):\n",
    "    \n",
    "    psig = 0\n",
    "    csig = 3./m.shape[0]\n",
    "    dsig = 1.\n",
    "    \n",
    "    pc = 0\n",
    "    cc = 4./m.shape[0]\n",
    "    c1 = 2/m.shape[0]**2\n",
    "    \n",
    "    E = np.sqrt(m.shape[0])*(1-1./(4*m.shape[0])+1./(21*m.shape[0]**2))\n",
    "    C = np.eye(m.shape[0])\n",
    "    for i in range(maxIter):\n",
    "        start = time.time()\n",
    "        y = np.random.multivariate_normal(mean=np.zeros(m.shape[0]),cov=C, size=L)\n",
    "        ps = np.apply_along_axis(lambda a: m + sigma*a, axis=1, arr=y)\n",
    "        #paraf = ps[j,:]\n",
    "        fs = np.apply_along_axis(f,axis=1,arr=ps)\n",
    "        #fs[j] = Predf(paraf,yT,x00,xT0)\n",
    "        \n",
    "        sortind = np.argsort(fs)\n",
    "        sortfs = fs[sortind]\n",
    "        print(\"func val = \", sortfs)\n",
    "        sortps = ps[sortind,:]\n",
    "        sorty = y[sortind,:]\n",
    "        \n",
    "        # update mean:\n",
    "        w = 1./mu\n",
    "        muw = 1./(mu*w**2)\n",
    "        mN = np.sum(w*sortps[0:mu,:], axis = 0)\n",
    "        \n",
    "        # update sigma:\n",
    "        yw = w*np.sum(sorty[0:mu,:], axis = 0)\n",
    "        psig = (1-csig)*psig + np.sqrt(1-(1-csig)**2)*np.sqrt(muw)*sp.linalg.sqrtm(invMatf(C))*yw\n",
    "        sigmaN = sigma*np.exp(csig/dsig*(np.linalg.norm(psig)/E -1))\n",
    "        \n",
    "        # update C:\n",
    "        k = 0\n",
    "        if np.linalg.norm(psig) <= 1.5*np.sqrt(m.shape[0]):\n",
    "            k = np.sqrt(1-(1-cc)**2)*np.sqrt(muw)*yw\n",
    "        pc = (1-cc)*pc + k\n",
    "        cmu = muw/m.shape[0]**2\n",
    "        CN = (1-c1-cmu)*C + c1*np.dot(pc,pc) + cmu*np.sum(w*np.dot(yw,yw.T))\n",
    "        \n",
    "        C = CN.copy()\n",
    "        sigma = sigmaN.copy()\n",
    "        m = mN.copy()\n",
    "        \n",
    "        diff = time.time() - start\n",
    "        print(\"time = \",diff)\n",
    "        \n",
    "        print(\"i = \", i, \" : mean = \", mN, \", sigma = \", sigmaN)\n",
    "        \n",
    "    return mN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraf = para0.copy()\n",
    "print(paraf)\n",
    "print(para0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sQ = fprov(50,40,15,0.5,np.array([0.8,1.3,2.3]))#paraIp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
